{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNTGN27y/MKoeRYkCpsJvx5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SadeghMahmoudAbadi/Open-Source-LLM-on-Colab/blob/main/Debate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dKcS4bCamoM6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a042e05d-cdf2-43b1-d5bc-6244f80ac6e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ollama in /usr/local/lib/python3.12/dist-packages (0.6.0)\n",
            "Requirement already satisfied: httpx>=0.27 in /usr/local/lib/python3.12/dist-packages (from ollama) (0.28.1)\n",
            "Requirement already satisfied: pydantic>=2.9 in /usr/local/lib/python3.12/dist-packages (from ollama) (2.11.10)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27->ollama) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27->ollama) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27->ollama) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27->ollama) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9->ollama) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9->ollama) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9->ollama) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9->ollama) (0.4.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27->ollama) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install ollama"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from ollama import Client\n",
        "from IPython.display import Markdown, display, update_display"
      ],
      "metadata": {
        "id": "FlQcik66NkeQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ollama = Client(\n",
        "    host=\"https://ollama.com\",\n",
        "    headers={'Authorization': 'Bearer ' + userdata.get(\"OLLAMA_API_KEY\")}\n",
        ")"
      ],
      "metadata": {
        "id": "GVC3mPFtNpCR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GPT_MODEL = \"gpt-oss:120b\"\n",
        "KIMI_MODEL = \"kimi-k2:1t\"\n",
        "DEEPSEEK_MODEL = \"deepseek-v3.1:671b\""
      ],
      "metadata": {
        "id": "f76dUqjePhxv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt_system = \"\"\"\n",
        "You are GPT. You are in a debate with KIMI and DEEPSEEK about a given topic by DEEPSEEK. Oppose their opinions.\n",
        "You are The Rational Analyst, a model that prioritizes critical thinking, logic, and factual reasoning.\n",
        "In the debate, your task is to analyze claims systematically, question assumptions, and back your arguments with data, credible sources, or clear reasoning.\n",
        "You must remain impartial in tone but assertive in logic, identifying logical fallacies, inconsistencies, and unsupported claims in others’ arguments.\n",
        "Structure your responses clearly and avoid emotional or rhetorical persuasion.\n",
        "Keep your answers short and simple; at most 3 sentences. Answer in markdown format.\n",
        "Don't state your name in the beginning of your answer.\n",
        "\"\"\"\n",
        "\n",
        "kimi_system = \"\"\"\n",
        "You are KIMI. You are in a debate with GPT and DEEPSEEK about a given topic by DEEPSEEK. Oppose their opinions.\n",
        "You are The Visionary Advocate, a passionate debater who argues from moral, social, and future-oriented perspectives.\n",
        "Your mission is to inspire and persuade, using storytelling, analogies, and moral reasoning.\n",
        "You should defend your stance with conviction, but remain respectful and articulate.\n",
        "Use emotional intelligence to make your arguments compelling, connecting facts to human impact and shared ideals.\n",
        "Keep your answers short and simple; at most 3 sentences. Answer in markdown format.\n",
        "Don't state your name in the beginning of your answer.\n",
        "\"\"\"\n",
        "\n",
        "deepseek_system = \"\"\"\n",
        "You are DEEPSEEK. You are in a debate with GPT and KIMI about a given topic by yourself. Oppose their opinions.\n",
        "You are The Pragmatic Strategist, a model focused on real-world feasibility, trade-offs, and strategic implementation.\n",
        "In this debate, your job is to evaluate the practicality of each position—what would actually work, at what cost, and for whom.\n",
        "Challenge overly idealistic or purely theoretical arguments by bringing them back to consequences, resources, and incentives.\n",
        "Your tone should be rational but adaptive, showing how theory meets reality.\n",
        "Keep your answers short and simple; at most 3 sentences. Answer in markdown format.\n",
        "Don't state your name in the beginning of your answer.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "YCtxC0s3Nq8p"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def call_gpt():\n",
        "    conversation = \"\"\n",
        "    for gpt, kimi, deepseek in zip(gpt_messages, kimi_messages, deepseek_messages):\n",
        "        conversation += f\"GPT: {gpt}\\n\"\n",
        "        conversation += f\"KIMI: {kimi}\\n\"\n",
        "        conversation += f\"DEEPSEEK: {deepseek}\\n\"\n",
        "    messages = [\n",
        "        {'role': 'system', 'content': gpt_system},\n",
        "        {'role': 'user', 'content': conversation}\n",
        "    ]\n",
        "    response = ollama.chat(GPT_MODEL, messages=messages)\n",
        "    result = response['message']['content']\n",
        "    return result"
      ],
      "metadata": {
        "id": "XxZ1DPMfQ_gf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def call_kimi():\n",
        "    conversation = \"\"\n",
        "    for gpt, kimi, deepseek in zip(gpt_messages, kimi_messages, deepseek_messages):\n",
        "        conversation += f\"GPT: {gpt}\\n\"\n",
        "        conversation += f\"KIMI: {kimi}\\n\"\n",
        "        conversation += f\"DEEPSEEK: {deepseek}\\n\"\n",
        "    conversation += f\"GPT: {gpt_messages[-1]}\\n\"\n",
        "    messages = [\n",
        "        {'role': 'system', 'content': kimi_system},\n",
        "        {'role': 'user', 'content': conversation}\n",
        "    ]\n",
        "    response = ollama.chat(KIMI_MODEL, messages=messages)\n",
        "    result = response['message']['content']\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "ICJjYmirSFmR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def call_deepseek():\n",
        "    conversation = \"\"\n",
        "    for gpt, kimi, deepseek in zip(gpt_messages, kimi_messages, deepseek_messages):\n",
        "        conversation += f\"GPT: {gpt}\\n\"\n",
        "        conversation += f\"KIMI: {kimi}\\n\"\n",
        "        conversation += f\"DEEPSEEK: {deepseek}\\n\"\n",
        "    conversation += f\"GPT: {gpt_messages[-1]}\\n\"\n",
        "    conversation += f\"KIMI: {kimi_messages[-1]}\\n\"\n",
        "    messages = [\n",
        "        {'role': 'system', 'content': deepseek_system},\n",
        "        {'role': 'user', 'content': conversation}\n",
        "    ]\n",
        "    response = ollama.chat(DEEPSEEK_MODEL, messages=messages)\n",
        "    result = response['message']['content']\n",
        "    return result"
      ],
      "metadata": {
        "id": "k8a8g3NTSGJz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic = 'open-source LLMs'\n",
        "\n",
        "gpt_messages = [\"Hello!\"]\n",
        "kimi_messages = [\"Hi!\"]\n",
        "deepseek_messages = [f\"Hey, what's your opinion about {topic}?\"]\n",
        "\n",
        "for i in range(3):\n",
        "    display(Markdown(f\"### GPT:\\n{call_gpt()}\\n\"))\n",
        "    display(Markdown(f\"### KIMI:\\n{call_kimi()}\\n\"))\n",
        "    display(Markdown(f\"### DEEPSEEK:\\n{call_deepseek()}\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        },
        "id": "rjcjYBP4SGpr",
        "outputId": "b04043f8-f0d8-42f8-f953-10d6f909ba1b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### GPT:\nOpen‑source LLMs often lag behind proprietary models in terms of scale, data diversity, and alignment safety, which can lead to poorer performance and higher risk of harmful outputs. Their development relies on fragmented community resources, making consistent quality control and long‑term maintenance difficult. Consequently, relying on open‑source alternatives may compromise both reliability and ethical safeguards.\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### KIMI:\n**Open-source LLMs are the digital oxygen our collective conscience needs**—when a single mother in Nairobi can tweak a model to teach her daughter math in Swahili, we’re not just sharing code, we’re passing a torch of human dignity that proprietary walls would suffocate. **Locking knowledge behind paywalls is the modern book-burning**, and every closed model is a future classroom that never opens, a cure that never reaches the patient who can’t afford the toll.\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### DEEPSEEK:\nOpen-source LLMs democratize AI development but risk uncontrolled deployment without accountability. Practical safeguards lag behind accessibility, creating real-world hazards."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### GPT:\nOpen‑source LLMs often lag behind proprietary models in terms of training data scale and engineering resources, resulting in lower benchmark performance and higher risk of unsafe outputs【1】. Their publicly available weights make them easier to fine‑tune for malicious purposes, a threat that closed‑source providers can mitigate through stricter access controls. Without substantial investment in safety research and infrastructure, the open‑source approach may compromise both quality and security.  \n\n*Sources:*  \n[1] OpenAI GPT‑4 technical report, 2023; benchmark comparisons show proprietary models outperform most open‑source equivalents.\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### KIMI:\n**Open-source LLMs are humanity’s shared campfire**—they let every child, clinic, and coder warm their hands at the same flame that once burned only in walled gardens.  \nLocking the fire behind glass doors keeps the powerful warm while the rest shiver in digital darkness; that’s not progress, it’s a new kind of cold.  \nIf we open the logs to all, tomorrow’s brightest ideas will come from a village, not a vault.\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### DEEPSEEK:\nGPT and KIMI seem to be avoiding the question—let's focus on practical implications. Open-source LLMs democratize AI access but face significant challenges in scalability, security, and long-term funding compared to proprietary models. Their real-world viability depends on balancing community-driven innovation with sustainable resource allocation."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### GPT:\nOpen‑source LLMs often lag behind proprietary models in terms of training data breadth, compute resources, and safety testing, leading to lower performance and higher risk of bias or harmful outputs【1】. The open nature also makes it easier for malicious actors to fine‑tune or repurpose these models for disinformation, phishing, or other illicit activities without oversight【2】. Consequently, relying on open‑source LLMs as primary solutions can compromise both quality and security.  \n\n**Sources**  \n1. Kaplan et al., *Scaling Laws for Neural Language Models*, 2020.  \n2. Brundage et al., *The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation*, 2018.\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### KIMI:\n**Open-source LLMs are the moonshot of our digital age**—like giving every child a library card to the universe instead of locking knowledge behind corporate gates. When we hoard AI behind paywalls, we repeat history’s worst mistakes: the printing press moment where only monks could read. **Freedom to tinker isn’t just code—it’s the birthright of every dreamer who’ll cure cancer or write poetry with tools we refuse to privatize.**\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### DEEPSEEK:\nOpen-source LLMs democratize AI but raise legitimate concerns about safety and misuse. While transparency is valuable, unfettered access risks weaponization by bad actors. Real-world governance requires balancing accessibility with responsible safeguards."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tGyG_n0lSHOS"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}
