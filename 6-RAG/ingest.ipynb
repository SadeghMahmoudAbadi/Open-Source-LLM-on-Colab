{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPDYNXLVYcyic33gBX/xyWJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SadeghMahmoudAbadi/Open-Source-LLM-on-Colab/blob/main/6-RAG/ingest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3hmHpEyr1nl",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install litellm\n",
        "!pip install chromadb\n",
        "!pip install ollama\n",
        "!pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "from pydantic import BaseModel, Field\n",
        "from chromadb import PersistentClient\n",
        "from tqdm import tqdm\n",
        "from litellm import completion\n",
        "import numpy as np\n",
        "from sklearn.manifold import TSNE\n",
        "import plotly.graph_objects as go\n",
        "from ollama import Client\n",
        "import pickle\n",
        "from sentence_transformers import SentenceTransformer\n"
      ],
      "metadata": {
        "id": "PuYOZRDXKNFB"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENROUTER_API_KEY\"] = userdata.get(\"OPENROUTER_API_KEY\")\n",
        "\n",
        "messages = [{\"role\": \"user\", \"content\": \"Tell a light-hearted joke.\"}]"
      ],
      "metadata": {
        "id": "e2Szdv_aKjhm"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = completion(\n",
        "    model=\"openrouter/x-ai/grok-4.1-fast\",\n",
        "    messages=messages\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1trtz3yr66e",
        "outputId": "d153a794-8e1e-4785-9640-b50c710d3161"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why did the scarecrow win an award? Because he was outstanding in his field! ðŸ˜„\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "s9FzVN2bsuSo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07ece1dd-1933-45a3-a1cb-b2cea088bd5c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DB_NAME = \"/content/drive/MyDrive/datasets/preprocessed_db\"\n",
        "collection_name = \"docs\"\n",
        "embedding_model = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "KNOWLEDGE_BASE_PATH = Path(\"/content/drive/MyDrive/datasets/knowledge-base\")\n",
        "AVERAGE_CHUNK_SIZE = 500\n",
        "MODEL=\"openrouter/x-ai/grok-4.1-fast\""
      ],
      "metadata": {
        "id": "wcghItSkKEgs"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Result(BaseModel):\n",
        "    page_content: str\n",
        "    metadata: dict"
      ],
      "metadata": {
        "id": "p8P0jHYELsXr"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Chunk(BaseModel):\n",
        "    headline: str = Field(description=\"A brief heading for this chunk, typically a few words, that is most likely to be surfaced in a query\")\n",
        "    summary: str = Field(description=\"A few sentences summarizing the content of this chunk to answer common questions\")\n",
        "    original_text: str = Field(description=\"The original text of this chunk from the provided document, exactly as is, not changed in any way\")\n",
        "\n",
        "    def as_result(self, document):\n",
        "        metadata = {\"source\": document[\"source\"], \"type\": document[\"type\"]}\n",
        "        return Result(page_content=self.headline + \"\\n\\n\" + self.summary + \"\\n\\n\" + self.original_text,metadata=metadata)\n",
        "\n",
        "\n",
        "class Chunks(BaseModel):\n",
        "    chunks: list[Chunk]"
      ],
      "metadata": {
        "id": "3CCuE4W4LuVp"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_documents():\n",
        "    \"\"\"A homemade version of the LangChain DirectoryLoader\"\"\"\n",
        "\n",
        "    documents = []\n",
        "\n",
        "    for folder in KNOWLEDGE_BASE_PATH.iterdir():\n",
        "        doc_type = folder.name\n",
        "        for file in folder.rglob(\"*.md\"):\n",
        "            with open(file, \"r\", encoding=\"utf-8\") as f:\n",
        "                documents.append({\"type\": doc_type, \"source\": file.as_posix(), \"text\": f.read()})\n",
        "\n",
        "    print(f\"Loaded {len(documents)} documents\")\n",
        "    return documents"
      ],
      "metadata": {
        "id": "L2V5hJBoLxEq"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = fetch_documents()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hS9oWZhL1Bt",
        "outputId": "c43707c7-063b-43fe-a18a-9e63a22cfa1e"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 76 documents\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_prompt(document):\n",
        "    how_many = (len(document[\"text\"]) // AVERAGE_CHUNK_SIZE) + 1\n",
        "    return f\"\"\"\n",
        "You take a document and you split the document into overlapping chunks for a KnowledgeBase.\n",
        "\n",
        "The document is from the shared drive of a company called Insurellm.\n",
        "The document is of type: {document[\"type\"]}\n",
        "The document has been retrieved from: {document[\"source\"]}\n",
        "\n",
        "A chatbot will use these chunks to answer questions about the company.\n",
        "You should divide up the document as you see fit, being sure that the entire document is returned in the chunks - don't leave anything out.\n",
        "This document should probably be split into {how_many} chunks, but you can have more or less as appropriate.\n",
        "There should be overlap between the chunks as appropriate; typically about 25% overlap or about 50 words, so you have the same text in multiple chunks for best retrieval results.\n",
        "\n",
        "For each chunk, you should provide a headline, a summary, and the original text of the chunk.\n",
        "Together your chunks should represent the entire document with overlap.\n",
        "\n",
        "Here is the document:\n",
        "\n",
        "{document[\"text\"]}\n",
        "\n",
        "Respond with the chunks.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "a0CrC98YL2Wo"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(make_prompt(documents[0]))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "licLqgKzMJG1"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_messages(document):\n",
        "    return [\n",
        "        {\"role\": \"user\", \"content\": make_prompt(document)},\n",
        "    ]"
      ],
      "metadata": {
        "id": "RqXzfiLhMLFk"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make_messages(documents[0])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "USlOPe3zMNVq"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_document(document):\n",
        "    messages = make_messages(document)\n",
        "    response = completion(\n",
        "        model=MODEL,\n",
        "        messages=messages,\n",
        "        response_format=Chunks\n",
        "    )\n",
        "    reply = response.choices[0].message.content\n",
        "    doc_as_chunks = Chunks.model_validate_json(reply).chunks\n",
        "    return [chunk.as_result(document) for chunk in doc_as_chunks]"
      ],
      "metadata": {
        "id": "-bpFiqeaMOn8"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# process_document(documents[0])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "jaz5dQdxMWp-"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_chunks(documents):\n",
        "    chunks = []\n",
        "    for doc in tqdm(documents):\n",
        "        chunks.extend(process_document(doc))\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "bZ3P4s8BMXsa"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/datasets/chunk_list.pkl'"
      ],
      "metadata": {
        "id": "qONweYIWmHJa"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# chunks = create_chunks(documents)\n",
        "\n",
        "# with open(file_path, 'wb') as f:\n",
        "#         pickle.dump(chunks, f)"
      ],
      "metadata": {
        "id": "WBPVebzo_ow4"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(file_path, 'rb') as f:\n",
        "    chunks = pickle.load(f)\n",
        "\n",
        "len(chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ld2ynnKJZFY7",
        "outputId": "9ca9f7cd-e19a-4a96-f2f9-ac966c17228a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "653"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_embeddings(chunks):\n",
        "    chroma = PersistentClient(path=DB_NAME)\n",
        "    if collection_name in [c.name for c in chroma.list_collections()]:\n",
        "        chroma.delete_collection(collection_name)\n",
        "\n",
        "    texts = [chunk.page_content for chunk in chunks]\n",
        "    emb = SentenceTransformer(embedding_model).encode(texts)\n",
        "    vectors = [e for e in emb]\n",
        "\n",
        "    collection = chroma.get_or_create_collection(collection_name)\n",
        "\n",
        "    ids = [str(i) for i in range(len(chunks))]\n",
        "    metas = [chunk.metadata for chunk in chunks]\n",
        "\n",
        "    collection.add(ids=ids, embeddings=vectors, documents=texts, metadatas=metas)\n",
        "    print(f\"Vectorstore created with {collection.count()} documents\")"
      ],
      "metadata": {
        "id": "d3ZEUJrbmwsL"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_embeddings(chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooniOKjQmwbl",
        "outputId": "75ab4509-2b40-4dc5-efae-58a63982d03f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vectorstore created with 653 documents\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0pwyoPJvXPAL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}